{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kl8d5SGugCPE",
        "outputId": "74ae4c11-ed04-45a1-f2f7-b12b80a088b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 2.122528553009033\n",
            "epoch: 100, cost: 0.28633204102516174\n",
            "epoch: 200, cost: 0.16716887056827545\n",
            "epoch: 300, cost: 0.10914496332406998\n",
            "epoch: 400, cost: 0.07707479596138\n",
            "epoch: 500, cost: 0.0574321411550045\n",
            "epoch: 600, cost: 0.044498953968286514\n",
            "epoch: 700, cost: 0.0355181023478508\n",
            "epoch: 800, cost: 0.029019854962825775\n",
            "epoch: 900, cost: 0.02416045591235161\n",
            "epoch: 1000, cost: 0.02042723074555397\n",
            "epoch: 1100, cost: 0.017493801191449165\n",
            "epoch: 1200, cost: 0.015144570730626583\n",
            "epoch: 1300, cost: 0.013232373632490635\n",
            "epoch: 1400, cost: 0.011653842404484749\n",
            "epoch: 1500, cost: 0.010334707796573639\n",
            "epoch: 1600, cost: 0.009220432490110397\n",
            "epoch: 1700, cost: 0.008270281367003918\n",
            "epoch: 1800, cost: 0.007453086320310831\n",
            "epoch: 1900, cost: 0.006745051592588425\n",
            "epoch: 2000, cost: 0.006127309985458851\n",
            "epoch: 2100, cost: 0.005585093051195145\n",
            "epoch: 2200, cost: 0.005106487311422825\n",
            "epoch: 2300, cost: 0.004681902471929789\n",
            "epoch: 2400, cost: 0.0043035028502345085\n",
            "epoch: 2500, cost: 0.003964859992265701\n",
            "epoch: 2600, cost: 0.0036605517379939556\n",
            "epoch: 2700, cost: 0.0033862211275845766\n",
            "epoch: 2800, cost: 0.003138028783723712\n",
            "epoch: 2900, cost: 0.0029127958696335554\n",
            "epoch: 3000, cost: 0.0027078604325652122\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "x_train = torch.FloatTensor([ [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], \n",
        "                             [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7] ])\n",
        "y_train = torch.FloatTensor([ [0,0,1], [0,0,1], [0,0,1], [0,1,0], \n",
        "                             [0,1,0], [0,1,0], [1,0,0], [1,0,0] ])\n",
        "\n",
        "W = torch.randn(4, 3, requires_grad=True)\n",
        "b = torch.randn(1, 3, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.Adam([W, b], lr=0.1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "    h = torch.softmax(torch.mm(x_train, W) + b, dim=1)\n",
        "    cost = -torch.mean(torch.sum(y_train * torch.log(h), dim=1))\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"epoch: {epoch}, cost: {cost.item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = torch.tensor([[1,11,10,9], [1,3,4,3], [1,1,0,1]], dtype=torch.float)\n",
        "h_test = torch.softmax(torch.mm(x_test, W) + b, dim=1)\n",
        "print(torch.argmax(h_test, dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQ7fJRN2g5z8",
        "outputId": "02675b61-4ccc-4565-f9ae-7de800d78ab2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 조금 더 깔끔하게 softmax\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "x_train = torch.FloatTensor([ [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], \n",
        "                             [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7] ])\n",
        "y_train = torch.tensor([2,2,2,1,1,1,0,0], dtype=torch.long)\n",
        "\n",
        "W = torch.randn(4, 3, requires_grad=True)\n",
        "b = torch.randn(1, 3, requires_grad=True)\n",
        "\n",
        "optimizer = torch.optim.Adam([W, b], lr=0.1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "    h = torch.mm(x_train, W) + b\n",
        "    cost = F.cross_entropy(h, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"epoch: {epoch}, cost: {cost.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNWR3Xs7jdgh",
        "outputId": "452a19e6-81ec-4a04-ae00-39d3e9d42bc1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 3.4084434509277344\n",
            "epoch: 100, cost: 0.3187463879585266\n",
            "epoch: 200, cost: 0.1977970153093338\n",
            "epoch: 300, cost: 0.13304364681243896\n",
            "epoch: 400, cost: 0.09584000706672668\n",
            "epoch: 500, cost: 0.07247481495141983\n",
            "epoch: 600, cost: 0.056776951998472214\n",
            "epoch: 700, cost: 0.045693956315517426\n",
            "epoch: 800, cost: 0.03756623715162277\n",
            "epoch: 900, cost: 0.03142291307449341\n",
            "epoch: 1000, cost: 0.026662757620215416\n",
            "epoch: 1100, cost: 0.022897085174918175\n",
            "epoch: 1200, cost: 0.019864948466420174\n",
            "epoch: 1300, cost: 0.01738608628511429\n",
            "epoch: 1400, cost: 0.015332491137087345\n",
            "epoch: 1500, cost: 0.013611461035907269\n",
            "epoch: 1600, cost: 0.01215424295514822\n",
            "epoch: 1700, cost: 0.010909237898886204\n",
            "epoch: 1800, cost: 0.009836784563958645\n",
            "epoch: 1900, cost: 0.008906271308660507\n",
            "epoch: 2000, cost: 0.008093559183180332\n",
            "epoch: 2100, cost: 0.007379488088190556\n",
            "epoch: 2200, cost: 0.006748746149241924\n",
            "epoch: 2300, cost: 0.00618881918489933\n",
            "epoch: 2400, cost: 0.005689526908099651\n",
            "epoch: 2500, cost: 0.00524246646091342\n",
            "epoch: 2600, cost: 0.004840611480176449\n",
            "epoch: 2700, cost: 0.004478199407458305\n",
            "epoch: 2800, cost: 0.00415016571059823\n",
            "epoch: 2900, cost: 0.003852491732686758\n",
            "epoch: 3000, cost: 0.0035815294831991196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "x_train = torch.FloatTensor([ [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5], \n",
        "                             [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7] ])\n",
        "y_train = torch.tensor([2,2,2,1,1,1,0,0], dtype=torch.long)\n",
        "\n",
        "model = nn.Linear(4, 3)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
        "\n",
        "for epoch in range(3001):\n",
        "    h = model(x_train)\n",
        "    cost = F.cross_entropy(h, y_train)\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"epoch: {epoch}, cost: {cost.item()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2SjA0jbmxWG",
        "outputId": "27a0782b-c361-444f-8160-89e2b2a9b54c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, cost: 2.752901077270508\n",
            "epoch: 100, cost: 0.35088929533958435\n",
            "epoch: 200, cost: 0.23120076954364777\n",
            "epoch: 300, cost: 0.16035033762454987\n",
            "epoch: 400, cost: 0.11759674549102783\n",
            "epoch: 500, cost: 0.08999765664339066\n",
            "epoch: 600, cost: 0.07109449058771133\n",
            "epoch: 700, cost: 0.057552438229322433\n",
            "epoch: 800, cost: 0.04751034080982208\n",
            "epoch: 900, cost: 0.03985556215047836\n",
            "epoch: 1000, cost: 0.03388640657067299\n",
            "epoch: 1100, cost: 0.02914140373468399\n",
            "epoch: 1200, cost: 0.025306852534413338\n",
            "epoch: 1300, cost: 0.022163312882184982\n",
            "epoch: 1400, cost: 0.019553910940885544\n",
            "epoch: 1500, cost: 0.017363550141453743\n",
            "epoch: 1600, cost: 0.015506889671087265\n",
            "epoch: 1700, cost: 0.013919147662818432\n",
            "epoch: 1800, cost: 0.01255072746425867\n",
            "epoch: 1900, cost: 0.011362805031239986\n",
            "epoch: 2000, cost: 0.010325019247829914\n",
            "epoch: 2100, cost: 0.009413057938218117\n",
            "epoch: 2200, cost: 0.008607360534369946\n",
            "epoch: 2300, cost: 0.007892083376646042\n",
            "epoch: 2400, cost: 0.007254274562001228\n",
            "epoch: 2500, cost: 0.006683215498924255\n",
            "epoch: 2600, cost: 0.006169966422021389\n",
            "epoch: 2700, cost: 0.005707078613340855\n",
            "epoch: 2800, cost: 0.005288241431117058\n",
            "epoch: 2900, cost: 0.00490815844386816\n",
            "epoch: 3000, cost: 0.004562261514365673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# softmax regression in sklearn\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "x_train = np.array([ [1,2,1,1], [2,1,3,2], [3,1,3,4], [4,1,5,5],\n",
        "                   [1,7,5,5], [1,2,5,6], [1,6,6,6], [1,7,7,7] ])\n",
        "y_train = np.array([ 2, 2, 2, 1, 1, 1, 0, 0 ])\n",
        "\n",
        "model = LogisticRegression(penalty='none')\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "x_test = np.array([[1,11,10,9], [1,3,4,3], [1,1,0,1]])\n",
        "\n",
        "print(model.predict(x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-217LN0AnRTa",
        "outputId": "3023436a-ecad-439b-c0cd-5b0836b10046"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 2]\n"
          ]
        }
      ]
    }
  ]
}